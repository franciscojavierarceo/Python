# PIPELINE DEFINITION
# Name: stock-data-elt-pipeline
# Description: Extract, Load, and Transform stock data, then train a model and make predictions.
# Inputs:
#    api_key: str
components:
  comp-fetch-stock-data:
    executorLabel: exec-fetch-stock-data
    inputDefinitions:
      parameters:
        api_key:
          parameterType: STRING
        output_dir:
          parameterType: STRING
  comp-make-predictions:
    executorLabel: exec-make-predictions
    inputDefinitions:
      parameters:
        data_dir:
          parameterType: STRING
        model_dir:
          parameterType: STRING
        output_dir:
          parameterType: STRING
  comp-materialize-online-store:
    executorLabel: exec-materialize-online-store
    inputDefinitions:
      parameters:
        data_dir:
          parameterType: STRING
        model_dir:
          parameterType: STRING
        output_dir:
          parameterType: STRING
  comp-process-data:
    executorLabel: exec-process-data
    inputDefinitions:
      parameters:
        input_dir:
          parameterType: STRING
        output_dir:
          parameterType: STRING
  comp-train-model:
    executorLabel: exec-train-model
    inputDefinitions:
      parameters:
        input_dir:
          parameterType: STRING
        output_dir:
          parameterType: STRING
deploymentSpec:
  executors:
    exec-fetch-stock-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - fetch_stock_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'aiohttp==3.9.5'\
          \ 'aiohttp-cors==0.7.0' 'aiosignal==1.3.1' 'annotated-types==0.7.0' 'anyio==4.4.0'\
          \ 'appnope==0.1.4' 'argon2-cffi==23.1.0' 'argon2-cffi-bindings==21.2.0'\
          \ 'arrow==1.3.0' 'asttokens==2.4.1' 'async-lru==2.0.4' 'async-timeout==4.0.3'\
          \ 'attrs==23.2.0' 'Babel==2.15.0' 'beautifulsoup4==4.12.3' 'black==23.3.0'\
          \ 'bleach==6.1.0' 'cachetools==5.4.0' 'certifi==2024.7.4' 'cffi==1.16.0'\
          \ 'charset-normalizer==3.3.2' 'click==8.1.7' 'cloudevents==1.11.0' 'cloudpickle==3.0.0'\
          \ 'colorama==0.4.6' 'colorful==0.5.6' 'comm==0.2.2' 'contourpy==1.2.1' 'cycler==0.12.1'\
          \ 'dask==2024.7.0' 'dask-expr==1.1.7' 'debugpy==1.8.2' 'decorator==5.1.1'\
          \ 'defusedxml==0.7.1' 'deprecation==2.1.0' 'dill==0.3.8' 'distlib==0.3.8'\
          \ 'dnspython==2.6.1' 'docstring_parser==0.16' 'email_validator==2.2.0' 'exceptiongroup==1.2.2'\
          \ 'executing==2.0.1' 'fastapi==0.109.2' 'fastapi-cli==0.0.4' 'fastjsonschema==2.20.0'\
          \ 'feast==0.39.1' 'filelock==3.15.4' 'fonttools==4.53.1' 'fqdn==1.5.1' 'frozenlist==1.4.1'\
          \ 'fsspec==2024.6.1' 'google-api-core==2.19.1' 'google-auth==2.32.0' 'google-cloud-core==2.4.1'\
          \ 'google-cloud-storage==2.17.0' 'google-crc32c==1.5.0' 'google-resumable-media==2.7.1'\
          \ 'googleapis-common-protos==1.63.2' 'grpcio==1.64.1' 'gunicorn==22.0.0'\
          \ 'h11==0.14.0' 'httpcore==1.0.5' 'httptools==0.6.1' 'httpx==0.26.0' 'idna==3.7'\
          \ 'importlib_metadata==8.0.0' 'ipykernel==6.29.5' 'ipython==8.26.0' 'ipywidgets==8.1.3'\
          \ 'isoduration==20.11.0' 'jedi==0.19.1' 'Jinja2==3.1.4' 'json5==0.9.25'\
          \ 'jsonpointer==3.0.0' 'jsonschema==4.23.0' 'jsonschema-specifications==2023.12.1'\
          \ 'jupyter==1.0.0' 'jupyter-console==6.6.3' 'jupyter-events==0.10.0' 'jupyter-lsp==2.2.5'\
          \ 'jupyter_client==8.6.2' 'jupyter_core==5.7.2' 'jupyter_server==2.14.2'\
          \ 'jupyter_server_terminals==0.5.3' 'jupyterlab==4.2.3' 'jupyterlab_pygments==0.3.0'\
          \ 'jupyterlab_server==2.27.2' 'jupyterlab_widgets==3.0.11' 'kfp==2.8.0'\
          \ 'kfp-pipeline-spec==0.3.0' 'kfp-server-api==2.0.5' 'kiwisolver==1.4.5'\
          \ 'kubernetes==26.1.0' 'locket==1.0.0' 'markdown-it-py==3.0.0' 'MarkupSafe==2.1.5'\
          \ 'matplotlib==3.9.1' 'matplotlib-inline==0.1.7' 'mdurl==0.1.2' 'mistune==3.0.2'\
          \ 'mmh3==4.1.0' 'mpmath==1.3.0' 'msgpack==1.0.8' 'multidict==6.0.5' 'mypy==1.10.1'\
          \ 'mypy-extensions==1.0.0' 'mypy-protobuf==3.6.0' 'nbclient==0.10.0' 'nbconvert==7.16.4'\
          \ 'nbformat==5.10.4' 'nest-asyncio==1.6.0' 'networkx==3.3' 'notebook==7.2.1'\
          \ 'notebook_shim==0.2.4' 'numpy==1.26.4' 'oauthlib==3.2.2' 'opencensus==0.11.4'\
          \ 'opencensus-context==0.1.3' 'orjson==3.10.6' 'overrides==7.7.0' 'packaging==24.1'\
          \ 'pandas==2.2.2' 'pandocfilters==1.5.1' 'parso==0.8.4' 'partd==1.4.2' 'pathspec==0.12.1'\
          \ 'pexpect==4.9.0' 'pillow==10.4.0' 'platformdirs==4.2.2' 'polygon-api-client==1.14.2'\
          \ 'prometheus_client==0.20.0' 'prompt_toolkit==3.0.47' 'proto-plus==1.24.0'\
          \ 'protobuf==4.25.3' 'psutil==5.9.8' 'ptyprocess==0.7.0' 'pure-eval==0.2.2'\
          \ 'py-spy==0.3.14' 'pyarrow==17.0.0' 'pyasn1==0.6.0' 'pyasn1_modules==0.4.0'\
          \ 'pycparser==2.22' 'pydantic==2.8.2' 'pydantic_core==2.20.1' 'Pygments==2.18.0'\
          \ 'pyparsing==3.1.2' 'python-dateutil==2.9.0.post0' 'python-dotenv==1.0.1'\
          \ 'python-json-logger==2.0.7' 'python-multipart==0.0.9' 'pytz==2024.1' 'PyYAML==6.0.1'\
          \ 'pyzmq==26.0.3' 'qtconsole==5.5.2' 'QtPy==2.4.1' 'ray==2.10.0' 'referencing==0.35.1'\
          \ 'requests==2.32.3' 'requests-oauthlib==2.0.0' 'requests-toolbelt==0.10.1'\
          \ 'rfc3339-validator==0.1.4' 'rfc3986-validator==0.1.1' 'rich==13.7.1' 'rpds-py==0.19.0'\
          \ 'rsa==4.9' 'Send2Trash==1.8.3' 'shellingham==1.5.4' 'six==1.16.0' 'smart-open==7.0.4'\
          \ 'sniffio==1.3.1' 'soupsieve==2.5' 'SQLAlchemy==2.0.31' 'stack-data==0.6.3'\
          \ 'starlette==0.36.3' 'sympy==1.13.0' 'tabulate==0.9.0' 'tenacity==8.5.0'\
          \ 'terminado==0.18.1' 'timing-asgi==0.3.1' 'tinycss2==1.3.0' 'toml==0.10.2'\
          \ 'tomli==2.0.1' 'toolz==0.12.1' 'torch==2.3.1' 'tornado==6.4.1' 'tqdm==4.66.4'\
          \ 'traitlets==5.14.3' 'typeguard==4.3.0' 'typer==0.12.3' 'types-protobuf==5.27.0.20240626'\
          \ 'types-python-dateutil==2.9.0.20240316' 'typing_extensions==4.12.2' 'tzdata==2024.1'\
          \ 'uri-template==1.3.0' 'urllib3==1.26.19' 'uvicorn==0.21.1' 'uvloop==0.19.0'\
          \ 'virtualenv==20.26.3' 'watchfiles==0.22.0' 'wcwidth==0.2.13' 'webcolors==24.6.0'\
          \ 'webencodings==0.5.1' 'websocket-client==1.8.0' 'websockets==12.0' 'widgetsnbextension==4.0.11'\
          \ 'wrapt==1.16.0' 'yarl==1.9.4' 'zipp==3.19.2' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef fetch_stock_data(api_key: str, output_dir: str) -> None:\n  \
          \  import sys\n    import subprocess\n    import time\n    import datetime\n\
          \    import os\n    import pickle\n    import pandas as pd\n    from polygon\
          \ import RESTClient\n\n    print(\"fetching stock data...\")\n    NDX_TICKER\
          \ = \"I:NDX\"\n    start_date = \"2024-01-01\"\n    output_filename = \"\
          ticker_data.pkl\"\n    log_file = \"successful_dates.log\"\n    todays_date\
          \ = datetime.datetime.now().date().strftime(\"%Y-%m-%d\")\n    client =\
          \ RESTClient(api_key)\n    stock_list = [\n        \"AAPL\",\n        \"\
          AMZN\",\n        \"GOOG\",\n        \"GOOGL\",\n        \"META\",\n    \
          \    \"MSFT\",\n        \"NVDA\",\n        \"TSLA\",\n    ]\n\n    def get_successful_dates(log_file:\
          \ str) -> set[str]:\n        if not os.path.exists(log_file):\n        \
          \    return set()\n        with open(log_file, \"r\") as f:\n          \
          \  dates = f.read().splitlines()\n        return set(dates)\n\n    def log_successful_dates(dates:\
          \ list[str], log_file: str) -> None:\n        with open(log_file, \"a\"\
          ) as f:\n            for date in dates:\n                f.write(f\"{date}\\\
          n\")\n\n    def get_dates_to_pull(\n        start_date: str, end_date: str,\
          \ successful_dates: list[str]\n    ) -> list[str]:\n        business_days\
          \ = (\n            pd.bdate_range(start_date, end_date).strftime(\"%Y-%m-%d\"\
          ).tolist()\n        )\n        return [date for date in business_days if\
          \ date not in successful_dates]\n\n    def pull_stock_data(ticker: str,\
          \ start_date: str) -> pd.DataFrame:\n        daily_ticker_data = []\n  \
          \      for ticker_agg in client.list_aggs(\n            ticker=ticker,\n\
          \            from_=start_date,\n            to=todays_date,\n          \
          \  multiplier=1,\n            timespan=\"day\",\n        ):\n          \
          \  daily_ticker_data.append(ticker_agg)\n\n        df = pd.DataFrame(daily_ticker_data)\n\
          \        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"ms\"\
          )\n        df[\"date\"] = df[\"timestamp\"].dt.date\n        return df\n\
          \n    def pull_all_stock_data(\n        ticker_list: list[str], start_date:\
          \ str, sleep_time: int = 30\n    ) -> dict:\n        stock_data_dict = {}\n\
          \        for ticker in ticker_list:\n            stock_data_dict[ticker]\
          \ = pull_stock_data(ticker, start_date)\n            time.sleep(sleep_time)\n\
          \        return stock_data_dict\n\n    def get_or_load_historical_data(\n\
          \        output_dir: str,\n        output_filename: str,\n        start_date:\
          \ str,\n    ) -> Tuple[pd.DataFrame, dict]:\n        if output_filename\
          \ in os.listdir(output_dir):\n            print(\"loading stored data...\"\
          )\n            with open(os.path.join(output_dir, output_filename), \"rb\"\
          ) as output_file:\n                df_dict = pickle.load(output_file)\n\
          \                ndx_df = df_dict[NDX_TICKER]\n        else:\n         \
          \   print(\"no stored data found, calling polygon api...\")\n          \
          \  ndx_df = pull_stock_data(NDX_TICKER, start_date)\n            df_dict\
          \ = pull_all_stock_data(stock_list, start_date)\n            df_dict[NDX_TICKER]\
          \ = ndx_df\n\n            with open(os.path.join(output_dir, output_filename),\
          \ \"wb\") as output_file:\n                pickle.dump(df_dict, output_file)\n\
          \        return ndx_df, df_dict\n\n    successful_dates = get_successful_dates(log_file)\n\
          \    dates_to_pull = get_dates_to_pull(start_date, todays_date, successful_dates)\n\
          \n    ndx_df, df_dict = get_or_load_historical_data(\n        output_dir,\n\
          \        output_filename,\n        start_date,\n    )\n\n"
        image: docker.io/library/python:3.10
    exec-make-predictions:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - make_predictions
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'aiohttp==3.9.5'\
          \ 'aiohttp-cors==0.7.0' 'aiosignal==1.3.1' 'annotated-types==0.7.0' 'anyio==4.4.0'\
          \ 'appnope==0.1.4' 'argon2-cffi==23.1.0' 'argon2-cffi-bindings==21.2.0'\
          \ 'arrow==1.3.0' 'asttokens==2.4.1' 'async-lru==2.0.4' 'async-timeout==4.0.3'\
          \ 'attrs==23.2.0' 'Babel==2.15.0' 'beautifulsoup4==4.12.3' 'black==23.3.0'\
          \ 'bleach==6.1.0' 'cachetools==5.4.0' 'certifi==2024.7.4' 'cffi==1.16.0'\
          \ 'charset-normalizer==3.3.2' 'click==8.1.7' 'cloudevents==1.11.0' 'cloudpickle==3.0.0'\
          \ 'colorama==0.4.6' 'colorful==0.5.6' 'comm==0.2.2' 'contourpy==1.2.1' 'cycler==0.12.1'\
          \ 'dask==2024.7.0' 'dask-expr==1.1.7' 'debugpy==1.8.2' 'decorator==5.1.1'\
          \ 'defusedxml==0.7.1' 'deprecation==2.1.0' 'dill==0.3.8' 'distlib==0.3.8'\
          \ 'dnspython==2.6.1' 'docstring_parser==0.16' 'email_validator==2.2.0' 'exceptiongroup==1.2.2'\
          \ 'executing==2.0.1' 'fastapi==0.109.2' 'fastapi-cli==0.0.4' 'fastjsonschema==2.20.0'\
          \ 'feast==0.39.1' 'filelock==3.15.4' 'fonttools==4.53.1' 'fqdn==1.5.1' 'frozenlist==1.4.1'\
          \ 'fsspec==2024.6.1' 'google-api-core==2.19.1' 'google-auth==2.32.0' 'google-cloud-core==2.4.1'\
          \ 'google-cloud-storage==2.17.0' 'google-crc32c==1.5.0' 'google-resumable-media==2.7.1'\
          \ 'googleapis-common-protos==1.63.2' 'grpcio==1.64.1' 'gunicorn==22.0.0'\
          \ 'h11==0.14.0' 'httpcore==1.0.5' 'httptools==0.6.1' 'httpx==0.26.0' 'idna==3.7'\
          \ 'importlib_metadata==8.0.0' 'ipykernel==6.29.5' 'ipython==8.26.0' 'ipywidgets==8.1.3'\
          \ 'isoduration==20.11.0' 'jedi==0.19.1' 'Jinja2==3.1.4' 'json5==0.9.25'\
          \ 'jsonpointer==3.0.0' 'jsonschema==4.23.0' 'jsonschema-specifications==2023.12.1'\
          \ 'jupyter==1.0.0' 'jupyter-console==6.6.3' 'jupyter-events==0.10.0' 'jupyter-lsp==2.2.5'\
          \ 'jupyter_client==8.6.2' 'jupyter_core==5.7.2' 'jupyter_server==2.14.2'\
          \ 'jupyter_server_terminals==0.5.3' 'jupyterlab==4.2.3' 'jupyterlab_pygments==0.3.0'\
          \ 'jupyterlab_server==2.27.2' 'jupyterlab_widgets==3.0.11' 'kfp==2.8.0'\
          \ 'kfp-pipeline-spec==0.3.0' 'kfp-server-api==2.0.5' 'kiwisolver==1.4.5'\
          \ 'kubernetes==26.1.0' 'locket==1.0.0' 'markdown-it-py==3.0.0' 'MarkupSafe==2.1.5'\
          \ 'matplotlib==3.9.1' 'matplotlib-inline==0.1.7' 'mdurl==0.1.2' 'mistune==3.0.2'\
          \ 'mmh3==4.1.0' 'mpmath==1.3.0' 'msgpack==1.0.8' 'multidict==6.0.5' 'mypy==1.10.1'\
          \ 'mypy-extensions==1.0.0' 'mypy-protobuf==3.6.0' 'nbclient==0.10.0' 'nbconvert==7.16.4'\
          \ 'nbformat==5.10.4' 'nest-asyncio==1.6.0' 'networkx==3.3' 'notebook==7.2.1'\
          \ 'notebook_shim==0.2.4' 'numpy==1.26.4' 'oauthlib==3.2.2' 'opencensus==0.11.4'\
          \ 'opencensus-context==0.1.3' 'orjson==3.10.6' 'overrides==7.7.0' 'packaging==24.1'\
          \ 'pandas==2.2.2' 'pandocfilters==1.5.1' 'parso==0.8.4' 'partd==1.4.2' 'pathspec==0.12.1'\
          \ 'pexpect==4.9.0' 'pillow==10.4.0' 'platformdirs==4.2.2' 'polygon-api-client==1.14.2'\
          \ 'prometheus_client==0.20.0' 'prompt_toolkit==3.0.47' 'proto-plus==1.24.0'\
          \ 'protobuf==4.25.3' 'psutil==5.9.8' 'ptyprocess==0.7.0' 'pure-eval==0.2.2'\
          \ 'py-spy==0.3.14' 'pyarrow==17.0.0' 'pyasn1==0.6.0' 'pyasn1_modules==0.4.0'\
          \ 'pycparser==2.22' 'pydantic==2.8.2' 'pydantic_core==2.20.1' 'Pygments==2.18.0'\
          \ 'pyparsing==3.1.2' 'python-dateutil==2.9.0.post0' 'python-dotenv==1.0.1'\
          \ 'python-json-logger==2.0.7' 'python-multipart==0.0.9' 'pytz==2024.1' 'PyYAML==6.0.1'\
          \ 'pyzmq==26.0.3' 'qtconsole==5.5.2' 'QtPy==2.4.1' 'ray==2.10.0' 'referencing==0.35.1'\
          \ 'requests==2.32.3' 'requests-oauthlib==2.0.0' 'requests-toolbelt==0.10.1'\
          \ 'rfc3339-validator==0.1.4' 'rfc3986-validator==0.1.1' 'rich==13.7.1' 'rpds-py==0.19.0'\
          \ 'rsa==4.9' 'Send2Trash==1.8.3' 'shellingham==1.5.4' 'six==1.16.0' 'smart-open==7.0.4'\
          \ 'sniffio==1.3.1' 'soupsieve==2.5' 'SQLAlchemy==2.0.31' 'stack-data==0.6.3'\
          \ 'starlette==0.36.3' 'sympy==1.13.0' 'tabulate==0.9.0' 'tenacity==8.5.0'\
          \ 'terminado==0.18.1' 'timing-asgi==0.3.1' 'tinycss2==1.3.0' 'toml==0.10.2'\
          \ 'tomli==2.0.1' 'toolz==0.12.1' 'torch==2.3.1' 'tornado==6.4.1' 'tqdm==4.66.4'\
          \ 'traitlets==5.14.3' 'typeguard==4.3.0' 'typer==0.12.3' 'types-protobuf==5.27.0.20240626'\
          \ 'types-python-dateutil==2.9.0.20240316' 'typing_extensions==4.12.2' 'tzdata==2024.1'\
          \ 'uri-template==1.3.0' 'urllib3==1.26.19' 'uvicorn==0.21.1' 'uvloop==0.19.0'\
          \ 'virtualenv==20.26.3' 'watchfiles==0.22.0' 'wcwidth==0.2.13' 'webcolors==24.6.0'\
          \ 'webencodings==0.5.1' 'websocket-client==1.8.0' 'websockets==12.0' 'widgetsnbextension==4.0.11'\
          \ 'wrapt==1.16.0' 'yarl==1.9.4' 'zipp==3.19.2' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef make_predictions(model_dir: str, data_dir: str, output_dir: str)\
          \ -> None:\n    import sys\n    import subprocess\n    import torch\n  \
          \  import torch.nn as nn\n    import os\n    import pandas as pd\n    import\
          \ numpy as np\n    import datetime\n\n    print(\"running predictions on\
          \ model...\")\n\n    class SimpleNN(nn.Module):\n        def __init__(self,\
          \ input_size, hidden_size, output_size):\n            super(SimpleNN, self).__init__()\n\
          \            self.fc1 = nn.Linear(input_size, hidden_size)\n           \
          \ self.relu = nn.ReLU()\n            self.fc2 = nn.Linear(hidden_size, output_size)\n\
          \n        def forward(self, x):\n            out = self.fc1(x)\n       \
          \     out = self.relu(out)\n            out = self.fc2(out)\n          \
          \  return out\n\n    df = pd.read_parquet(data_dir)\n\n    feature_list\
          \ = sorted(\n        [c for c in df.columns if (\"lag_\" in c or \"window_\"\
          \ in c) and \"ndx\" not in c]\n    )\n    features = torch.from_numpy(df[feature_list].values[5:,\
          \ :].astype(np.float32))\n    labels = torch.from_numpy(df[\"open_i:ndx\"\
          ].values[5:].astype(np.float32))\n\n    input_size = features.shape[1]\n\
          \    hidden_size = 32\n    output_size = 1\n    model = SimpleNN(input_size,\
          \ hidden_size, output_size)\n    model.load_state_dict(torch.load(os.path.join(model_dir,\
          \ \"model.pth\")))\n    model.eval()\n\n    with torch.no_grad():\n    \
          \    predictions = model(features)\n\n    print(f\"RMSE = {torch.sqrt(torch.mean(\
          \ (predictions - labels) ** 2) )}\")\n    df.loc[5:, \"predictions\"] =\
          \ predictions.numpy()\n    df[\"run_date\"] = datetime.datetime.now().date().strftime(\"\
          %Y-%m-%d\")\n\n    os.makedirs(output_dir, exist_ok=True)\n    dfss = df[[\"\
          date_i:ndx\", \"open_i:ndx\", \"predictions\", \"run_date\"]]\n    dfss.to_parquet(os.path.join(output_dir,\
          \ \"predictions.parquet\"), index=False)\n    print(f\"predictions =\\n{dfss.tail()}\"\
          )\n\n"
        image: docker.io/library/python:3.10
    exec-materialize-online-store:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - materialize_online_store
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.8.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef materialize_online_store(model_dir: str, data_dir: str, output_dir:\
          \ str) -> None:\n    import feast\n\n    print(feast.__version__)\n\n"
        image: python:3.8
    exec-process-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - process_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'aiohttp==3.9.5'\
          \ 'aiohttp-cors==0.7.0' 'aiosignal==1.3.1' 'annotated-types==0.7.0' 'anyio==4.4.0'\
          \ 'appnope==0.1.4' 'argon2-cffi==23.1.0' 'argon2-cffi-bindings==21.2.0'\
          \ 'arrow==1.3.0' 'asttokens==2.4.1' 'async-lru==2.0.4' 'async-timeout==4.0.3'\
          \ 'attrs==23.2.0' 'Babel==2.15.0' 'beautifulsoup4==4.12.3' 'black==23.3.0'\
          \ 'bleach==6.1.0' 'cachetools==5.4.0' 'certifi==2024.7.4' 'cffi==1.16.0'\
          \ 'charset-normalizer==3.3.2' 'click==8.1.7' 'cloudevents==1.11.0' 'cloudpickle==3.0.0'\
          \ 'colorama==0.4.6' 'colorful==0.5.6' 'comm==0.2.2' 'contourpy==1.2.1' 'cycler==0.12.1'\
          \ 'dask==2024.7.0' 'dask-expr==1.1.7' 'debugpy==1.8.2' 'decorator==5.1.1'\
          \ 'defusedxml==0.7.1' 'deprecation==2.1.0' 'dill==0.3.8' 'distlib==0.3.8'\
          \ 'dnspython==2.6.1' 'docstring_parser==0.16' 'email_validator==2.2.0' 'exceptiongroup==1.2.2'\
          \ 'executing==2.0.1' 'fastapi==0.109.2' 'fastapi-cli==0.0.4' 'fastjsonschema==2.20.0'\
          \ 'feast==0.39.1' 'filelock==3.15.4' 'fonttools==4.53.1' 'fqdn==1.5.1' 'frozenlist==1.4.1'\
          \ 'fsspec==2024.6.1' 'google-api-core==2.19.1' 'google-auth==2.32.0' 'google-cloud-core==2.4.1'\
          \ 'google-cloud-storage==2.17.0' 'google-crc32c==1.5.0' 'google-resumable-media==2.7.1'\
          \ 'googleapis-common-protos==1.63.2' 'grpcio==1.64.1' 'gunicorn==22.0.0'\
          \ 'h11==0.14.0' 'httpcore==1.0.5' 'httptools==0.6.1' 'httpx==0.26.0' 'idna==3.7'\
          \ 'importlib_metadata==8.0.0' 'ipykernel==6.29.5' 'ipython==8.26.0' 'ipywidgets==8.1.3'\
          \ 'isoduration==20.11.0' 'jedi==0.19.1' 'Jinja2==3.1.4' 'json5==0.9.25'\
          \ 'jsonpointer==3.0.0' 'jsonschema==4.23.0' 'jsonschema-specifications==2023.12.1'\
          \ 'jupyter==1.0.0' 'jupyter-console==6.6.3' 'jupyter-events==0.10.0' 'jupyter-lsp==2.2.5'\
          \ 'jupyter_client==8.6.2' 'jupyter_core==5.7.2' 'jupyter_server==2.14.2'\
          \ 'jupyter_server_terminals==0.5.3' 'jupyterlab==4.2.3' 'jupyterlab_pygments==0.3.0'\
          \ 'jupyterlab_server==2.27.2' 'jupyterlab_widgets==3.0.11' 'kfp==2.8.0'\
          \ 'kfp-pipeline-spec==0.3.0' 'kfp-server-api==2.0.5' 'kiwisolver==1.4.5'\
          \ 'kubernetes==26.1.0' 'locket==1.0.0' 'markdown-it-py==3.0.0' 'MarkupSafe==2.1.5'\
          \ 'matplotlib==3.9.1' 'matplotlib-inline==0.1.7' 'mdurl==0.1.2' 'mistune==3.0.2'\
          \ 'mmh3==4.1.0' 'mpmath==1.3.0' 'msgpack==1.0.8' 'multidict==6.0.5' 'mypy==1.10.1'\
          \ 'mypy-extensions==1.0.0' 'mypy-protobuf==3.6.0' 'nbclient==0.10.0' 'nbconvert==7.16.4'\
          \ 'nbformat==5.10.4' 'nest-asyncio==1.6.0' 'networkx==3.3' 'notebook==7.2.1'\
          \ 'notebook_shim==0.2.4' 'numpy==1.26.4' 'oauthlib==3.2.2' 'opencensus==0.11.4'\
          \ 'opencensus-context==0.1.3' 'orjson==3.10.6' 'overrides==7.7.0' 'packaging==24.1'\
          \ 'pandas==2.2.2' 'pandocfilters==1.5.1' 'parso==0.8.4' 'partd==1.4.2' 'pathspec==0.12.1'\
          \ 'pexpect==4.9.0' 'pillow==10.4.0' 'platformdirs==4.2.2' 'polygon-api-client==1.14.2'\
          \ 'prometheus_client==0.20.0' 'prompt_toolkit==3.0.47' 'proto-plus==1.24.0'\
          \ 'protobuf==4.25.3' 'psutil==5.9.8' 'ptyprocess==0.7.0' 'pure-eval==0.2.2'\
          \ 'py-spy==0.3.14' 'pyarrow==17.0.0' 'pyasn1==0.6.0' 'pyasn1_modules==0.4.0'\
          \ 'pycparser==2.22' 'pydantic==2.8.2' 'pydantic_core==2.20.1' 'Pygments==2.18.0'\
          \ 'pyparsing==3.1.2' 'python-dateutil==2.9.0.post0' 'python-dotenv==1.0.1'\
          \ 'python-json-logger==2.0.7' 'python-multipart==0.0.9' 'pytz==2024.1' 'PyYAML==6.0.1'\
          \ 'pyzmq==26.0.3' 'qtconsole==5.5.2' 'QtPy==2.4.1' 'ray==2.10.0' 'referencing==0.35.1'\
          \ 'requests==2.32.3' 'requests-oauthlib==2.0.0' 'requests-toolbelt==0.10.1'\
          \ 'rfc3339-validator==0.1.4' 'rfc3986-validator==0.1.1' 'rich==13.7.1' 'rpds-py==0.19.0'\
          \ 'rsa==4.9' 'Send2Trash==1.8.3' 'shellingham==1.5.4' 'six==1.16.0' 'smart-open==7.0.4'\
          \ 'sniffio==1.3.1' 'soupsieve==2.5' 'SQLAlchemy==2.0.31' 'stack-data==0.6.3'\
          \ 'starlette==0.36.3' 'sympy==1.13.0' 'tabulate==0.9.0' 'tenacity==8.5.0'\
          \ 'terminado==0.18.1' 'timing-asgi==0.3.1' 'tinycss2==1.3.0' 'toml==0.10.2'\
          \ 'tomli==2.0.1' 'toolz==0.12.1' 'torch==2.3.1' 'tornado==6.4.1' 'tqdm==4.66.4'\
          \ 'traitlets==5.14.3' 'typeguard==4.3.0' 'typer==0.12.3' 'types-protobuf==5.27.0.20240626'\
          \ 'types-python-dateutil==2.9.0.20240316' 'typing_extensions==4.12.2' 'tzdata==2024.1'\
          \ 'uri-template==1.3.0' 'urllib3==1.26.19' 'uvicorn==0.21.1' 'uvloop==0.19.0'\
          \ 'virtualenv==20.26.3' 'watchfiles==0.22.0' 'wcwidth==0.2.13' 'webcolors==24.6.0'\
          \ 'webencodings==0.5.1' 'websocket-client==1.8.0' 'websockets==12.0' 'widgetsnbextension==4.0.11'\
          \ 'wrapt==1.16.0' 'yarl==1.9.4' 'zipp==3.19.2' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef process_data(input_dir: str, output_dir: str) -> None:\n    import\
          \ os\n    import sys\n    import pandas as pd\n    import subprocess\n \
          \   import pickle\n\n    print(\"processing data...\")\n    with open(os.path.join(input_dir,\
          \ \"ticker_data.pkl\"), \"rb\") as input_file:\n        df_dict = pickle.load(input_file)\n\
          \n    NDX_TICKER = \"I:NDX\"\n    columns_to_process = [\"open\", \"low\"\
          , \"high\"]\n    n_lags, max_window_size = 5, 5\n\n    def generate_lag_features(df:\
          \ pd.DataFrame, column: str, n_lags: int = 5) -> None:\n        for t in\
          \ range(1, n_lags + 1):\n            df[f\"{column}_lag{t}\"] = df[f\"{column}\"\
          ].shift(t)\n\n    def calculate_sliding_window_averages(\n        df: pd.DataFrame,\
          \ field_name: str, max_window_size: int = 5\n    ) -> None:\n        for\
          \ window_size in range(1, max_window_size + 1):\n            for i in range(1,\
          \ max_window_size - window_size + 1):\n                column_name = f\"\
          {field_name}_window_avg_from_{i}_to_{i+window_size}\"\n                columns_to_window\
          \ = [\n                    f\"{field_name}_lag{c}\" for c in range(i, i\
          \ + window_size + 1)\n                ]\n                df[column_name]\
          \ = df[columns_to_window].mean(axis=1)\n\n    def run_feature_pipeline(\n\
          \        df: pd.DataFrame, features: list[str], n_lags: int = 5, max_window_size:\
          \ int = 5\n    ) -> None:\n        for c in features:\n            generate_lag_features(df,\
          \ c, n_lags)\n            calculate_sliding_window_averages(df, c, max_window_size)\n\
          \n    def create_model_dataset(\n        df: pd.DataFrame,\n        main_ticker:\
          \ str,\n        columns_to_process: list[str],\n        ticker_df_dict:\
          \ dict,\n        n_lags: int,\n        max_window_size: int,\n    ) -> pd.DataFrame:\n\
          \        finaldf = df.copy()\n        run_feature_pipeline(df, columns_to_process,\
          \ n_lags, max_window_size)\n        finaldf.columns = [f\"{c}_{main_ticker.lower()}\"\
          \ for c in finaldf.columns]\n\n        for ticker in ticker_df_dict:\n \
          \           if ticker != main_ticker:\n                ticker_df = ticker_df_dict[ticker].copy()\n\
          \                run_feature_pipeline(\n                    ticker_df, columns_to_process,\
          \ n_lags, max_window_size\n                )\n                finaldf =\
          \ finaldf.merge(\n                    ticker_df.rename(\n              \
          \          columns={c: f\"{c}_{ticker.lower()}\" for c in ticker_df.columns}\n\
          \                    ),\n                    how=\"left\",\n           \
          \         left_on=f\"date_{main_ticker.lower()}\",\n                   \
          \ right_on=f\"date_{ticker.lower()}\",\n                )\n\n        finaldf.drop_duplicates(subset=[f\"\
          date_{main_ticker.lower()}\"], inplace=True)\n        return finaldf\n\n\
          \    def save_data_to_parquet(df: pd.DataFrame, base_path: str):\n     \
          \   unique_dates = df[\"date_i:ndx\"].astype(str).unique().tolist()\n  \
          \      missing_dates = [\n            j for j in unique_dates if f\"date_i:ndx={j}\"\
          \ not in os.listdir(base_path)\n        ]\n        if len(missing_dates)\
          \ > 0:\n            print(f\"exporting {len(missing_dates)} more file(s)\"\
          )\n            dfss = df[\n                df[\"date_i:ndx\"].astype(str).str.contains(\"\
          |\".join(missing_dates))\n            ]\n            dfss.to_parquet(base_path,\
          \ index=False, partition_cols=[\"date_i:ndx\"])\n        else:\n       \
          \     print(\"exporting 0 files - no new data found\")\n\n    ndx_df = df_dict[NDX_TICKER]\n\
          \    finaldf = create_model_dataset(\n        ndx_df, NDX_TICKER, columns_to_process,\
          \ df_dict, n_lags, max_window_size\n    )\n\n    os.makedirs(output_dir,\
          \ exist_ok=True)\n    save_data_to_parquet(finaldf, os.path.join(output_dir))\n\
          \    print(f\"{finaldf.shape[0]} records in dataset...\")\n\n"
        image: docker.io/library/python:3.10
    exec-train-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - train_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'aiohttp==3.9.5'\
          \ 'aiohttp-cors==0.7.0' 'aiosignal==1.3.1' 'annotated-types==0.7.0' 'anyio==4.4.0'\
          \ 'appnope==0.1.4' 'argon2-cffi==23.1.0' 'argon2-cffi-bindings==21.2.0'\
          \ 'arrow==1.3.0' 'asttokens==2.4.1' 'async-lru==2.0.4' 'async-timeout==4.0.3'\
          \ 'attrs==23.2.0' 'Babel==2.15.0' 'beautifulsoup4==4.12.3' 'black==23.3.0'\
          \ 'bleach==6.1.0' 'cachetools==5.4.0' 'certifi==2024.7.4' 'cffi==1.16.0'\
          \ 'charset-normalizer==3.3.2' 'click==8.1.7' 'cloudevents==1.11.0' 'cloudpickle==3.0.0'\
          \ 'colorama==0.4.6' 'colorful==0.5.6' 'comm==0.2.2' 'contourpy==1.2.1' 'cycler==0.12.1'\
          \ 'dask==2024.7.0' 'dask-expr==1.1.7' 'debugpy==1.8.2' 'decorator==5.1.1'\
          \ 'defusedxml==0.7.1' 'deprecation==2.1.0' 'dill==0.3.8' 'distlib==0.3.8'\
          \ 'dnspython==2.6.1' 'docstring_parser==0.16' 'email_validator==2.2.0' 'exceptiongroup==1.2.2'\
          \ 'executing==2.0.1' 'fastapi==0.109.2' 'fastapi-cli==0.0.4' 'fastjsonschema==2.20.0'\
          \ 'feast==0.39.1' 'filelock==3.15.4' 'fonttools==4.53.1' 'fqdn==1.5.1' 'frozenlist==1.4.1'\
          \ 'fsspec==2024.6.1' 'google-api-core==2.19.1' 'google-auth==2.32.0' 'google-cloud-core==2.4.1'\
          \ 'google-cloud-storage==2.17.0' 'google-crc32c==1.5.0' 'google-resumable-media==2.7.1'\
          \ 'googleapis-common-protos==1.63.2' 'grpcio==1.64.1' 'gunicorn==22.0.0'\
          \ 'h11==0.14.0' 'httpcore==1.0.5' 'httptools==0.6.1' 'httpx==0.26.0' 'idna==3.7'\
          \ 'importlib_metadata==8.0.0' 'ipykernel==6.29.5' 'ipython==8.26.0' 'ipywidgets==8.1.3'\
          \ 'isoduration==20.11.0' 'jedi==0.19.1' 'Jinja2==3.1.4' 'json5==0.9.25'\
          \ 'jsonpointer==3.0.0' 'jsonschema==4.23.0' 'jsonschema-specifications==2023.12.1'\
          \ 'jupyter==1.0.0' 'jupyter-console==6.6.3' 'jupyter-events==0.10.0' 'jupyter-lsp==2.2.5'\
          \ 'jupyter_client==8.6.2' 'jupyter_core==5.7.2' 'jupyter_server==2.14.2'\
          \ 'jupyter_server_terminals==0.5.3' 'jupyterlab==4.2.3' 'jupyterlab_pygments==0.3.0'\
          \ 'jupyterlab_server==2.27.2' 'jupyterlab_widgets==3.0.11' 'kfp==2.8.0'\
          \ 'kfp-pipeline-spec==0.3.0' 'kfp-server-api==2.0.5' 'kiwisolver==1.4.5'\
          \ 'kubernetes==26.1.0' 'locket==1.0.0' 'markdown-it-py==3.0.0' 'MarkupSafe==2.1.5'\
          \ 'matplotlib==3.9.1' 'matplotlib-inline==0.1.7' 'mdurl==0.1.2' 'mistune==3.0.2'\
          \ 'mmh3==4.1.0' 'mpmath==1.3.0' 'msgpack==1.0.8' 'multidict==6.0.5' 'mypy==1.10.1'\
          \ 'mypy-extensions==1.0.0' 'mypy-protobuf==3.6.0' 'nbclient==0.10.0' 'nbconvert==7.16.4'\
          \ 'nbformat==5.10.4' 'nest-asyncio==1.6.0' 'networkx==3.3' 'notebook==7.2.1'\
          \ 'notebook_shim==0.2.4' 'numpy==1.26.4' 'oauthlib==3.2.2' 'opencensus==0.11.4'\
          \ 'opencensus-context==0.1.3' 'orjson==3.10.6' 'overrides==7.7.0' 'packaging==24.1'\
          \ 'pandas==2.2.2' 'pandocfilters==1.5.1' 'parso==0.8.4' 'partd==1.4.2' 'pathspec==0.12.1'\
          \ 'pexpect==4.9.0' 'pillow==10.4.0' 'platformdirs==4.2.2' 'polygon-api-client==1.14.2'\
          \ 'prometheus_client==0.20.0' 'prompt_toolkit==3.0.47' 'proto-plus==1.24.0'\
          \ 'protobuf==4.25.3' 'psutil==5.9.8' 'ptyprocess==0.7.0' 'pure-eval==0.2.2'\
          \ 'py-spy==0.3.14' 'pyarrow==17.0.0' 'pyasn1==0.6.0' 'pyasn1_modules==0.4.0'\
          \ 'pycparser==2.22' 'pydantic==2.8.2' 'pydantic_core==2.20.1' 'Pygments==2.18.0'\
          \ 'pyparsing==3.1.2' 'python-dateutil==2.9.0.post0' 'python-dotenv==1.0.1'\
          \ 'python-json-logger==2.0.7' 'python-multipart==0.0.9' 'pytz==2024.1' 'PyYAML==6.0.1'\
          \ 'pyzmq==26.0.3' 'qtconsole==5.5.2' 'QtPy==2.4.1' 'ray==2.10.0' 'referencing==0.35.1'\
          \ 'requests==2.32.3' 'requests-oauthlib==2.0.0' 'requests-toolbelt==0.10.1'\
          \ 'rfc3339-validator==0.1.4' 'rfc3986-validator==0.1.1' 'rich==13.7.1' 'rpds-py==0.19.0'\
          \ 'rsa==4.9' 'Send2Trash==1.8.3' 'shellingham==1.5.4' 'six==1.16.0' 'smart-open==7.0.4'\
          \ 'sniffio==1.3.1' 'soupsieve==2.5' 'SQLAlchemy==2.0.31' 'stack-data==0.6.3'\
          \ 'starlette==0.36.3' 'sympy==1.13.0' 'tabulate==0.9.0' 'tenacity==8.5.0'\
          \ 'terminado==0.18.1' 'timing-asgi==0.3.1' 'tinycss2==1.3.0' 'toml==0.10.2'\
          \ 'tomli==2.0.1' 'toolz==0.12.1' 'torch==2.3.1' 'tornado==6.4.1' 'tqdm==4.66.4'\
          \ 'traitlets==5.14.3' 'typeguard==4.3.0' 'typer==0.12.3' 'types-protobuf==5.27.0.20240626'\
          \ 'types-python-dateutil==2.9.0.20240316' 'typing_extensions==4.12.2' 'tzdata==2024.1'\
          \ 'uri-template==1.3.0' 'urllib3==1.26.19' 'uvicorn==0.21.1' 'uvloop==0.19.0'\
          \ 'virtualenv==20.26.3' 'watchfiles==0.22.0' 'wcwidth==0.2.13' 'webcolors==24.6.0'\
          \ 'webencodings==0.5.1' 'websocket-client==1.8.0' 'websockets==12.0' 'widgetsnbextension==4.0.11'\
          \ 'wrapt==1.16.0' 'yarl==1.9.4' 'zipp==3.19.2' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef train_model(input_dir: str, output_dir: str) -> None:\n    import\
          \ sys\n    import subprocess\n    import torch\n    import torch.nn as nn\n\
          \    import torch.optim as optim\n    import os\n    import pandas as pd\n\
          \    import numpy as np\n\n    print(\"training model...\")\n\n    class\
          \ SimpleNN(nn.Module):\n        def __init__(self, input_size, hidden_size,\
          \ output_size):\n            super(SimpleNN, self).__init__()\n        \
          \    self.fc1 = nn.Linear(input_size, hidden_size)\n            self.relu\
          \ = nn.ReLU()\n            self.fc2 = nn.Linear(hidden_size, output_size)\n\
          \n        def forward(self, x):\n            out = self.fc1(x)\n       \
          \     out = self.relu(out)\n            out = self.fc2(out)\n          \
          \  return out\n\n    df = pd.read_parquet(input_dir)\n\n    feature_list\
          \ = sorted(\n        [c for c in df.columns if (\"lag_\" in c or \"window_\"\
          \ in c) and \"ndx\" not in c]\n    )\n    features = torch.from_numpy(df[feature_list].values[5:,\
          \ :].astype(np.float32))\n    labels = torch.from_numpy(df[\"open_i:ndx\"\
          ].values[5:].astype(np.float32))\n\n    input_size = features.shape[1]\n\
          \    hidden_size = 32\n    output_size = 1\n    model = SimpleNN(input_size,\
          \ hidden_size, output_size)\n\n    criterion = nn.MSELoss()\n    optimizer\
          \ = optim.Adam(model.parameters(), lr=0.1)\n\n    num_epochs = 200\n   \
          \ for epoch in range(num_epochs):\n        outputs = model(features)\n \
          \       loss = criterion(outputs, labels.view(-1, 1))\n        optimizer.zero_grad()\n\
          \        loss.backward()\n        optimizer.step()\n\n    os.makedirs(output_dir,\
          \ exist_ok=True)\n    torch.save(model.state_dict(), os.path.join(output_dir,\
          \ \"model.pth\"))\n\n"
        image: docker.io/library/python:3.10
pipelineInfo:
  description: Extract, Load, and Transform stock data, then train a model and make
    predictions.
  name: stock-data-elt-pipeline
root:
  dag:
    tasks:
      fetch-stock-data:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-fetch-stock-data
        inputs:
          parameters:
            api_key:
              componentInputParameter: api_key
            output_dir:
              runtimeValue:
                constant: ./archive
        taskInfo:
          name: fetch-stock-data
      make-predictions:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-make-predictions
        dependentTasks:
        - train-model
        inputs:
          parameters:
            data_dir:
              runtimeValue:
                constant: ./data
            model_dir:
              runtimeValue:
                constant: ./model
            output_dir:
              runtimeValue:
                constant: ./predictions
        taskInfo:
          name: make-predictions
      materialize-online-store:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-materialize-online-store
        dependentTasks:
        - make-predictions
        inputs:
          parameters:
            data_dir:
              runtimeValue:
                constant: ./data
            model_dir:
              runtimeValue:
                constant: ./model
            output_dir:
              runtimeValue:
                constant: ./predictions
        taskInfo:
          name: materialize-online-store
      process-data:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-process-data
        dependentTasks:
        - fetch-stock-data
        inputs:
          parameters:
            input_dir:
              runtimeValue:
                constant: ./archive
            output_dir:
              runtimeValue:
                constant: ./data
        taskInfo:
          name: process-data
      train-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-train-model
        dependentTasks:
        - process-data
        inputs:
          parameters:
            input_dir:
              runtimeValue:
                constant: ./data
            output_dir:
              runtimeValue:
                constant: ./model
        taskInfo:
          name: train-model
  inputDefinitions:
    parameters:
      api_key:
        parameterType: STRING
schemaVersion: 2.1.0
sdkVersion: kfp-2.8.0
